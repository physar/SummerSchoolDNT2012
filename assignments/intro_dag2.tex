\documentclass[a4paper]{article}

\usepackage{hyperref}

\title{\textbf{Robotics Summerschool Juli 2012} \\ Introductie opdrachten Dag 2}
\author{Dutch Nao Team - \url{http://dutchnaoteam.nl}}
\date{}

\begin{document}
\maketitle

\section{Introductie}
Welkom bij de Summerschool Robotics.

Download de code van .....
Unzip het 

blabla

veel plezier!


\tableofcontents

\newpage


\section{Opdrachten}
Voor de vision opdrachten maken we gebruik van Open CV. Dit is een Computer Vision library die door meerdere programmeertalen kan worden gebruikt voor beeld verwerking.

\subsection{Framework update}
Om de robot de weg te laten vinden, moet deze gebruik maken van zijn camera. Een Nao heeft 2 camera's in zijn hoofd zitten: in zijn mond en in zijn voorhoofd. Wij zullen enkel de camera in de mond gebruiken.

Net als bij motions, wordt de camera ook via een proxy aangeroepen. Door \textit{self.vidProxy = ALProxy( "ALVideoDevice", self.ipadress, 9559 )} toe te voegen aan de \textit{setProxies()} functie krijgen we de mogelijkheid om te camera in te lezen. Voordat we een foto maken moeten er nog enkele camera parameters worden ingesteld. Dit wordt gedaan door de \textit{cSubscribe()} functie in de \textit{tools} module: voeg daarom deze module toe aan \textit{config.py} (de tools-module staat in de \textit{lib}).

Het is aan te raden op voor deze dag een nieuw main-module te maken. Zorg ervoor dat de nieuwe main-module, de globals, motions en tools-module kan gebruiken. Initializeer daarna in de \textit{start()} functie de proxies, motions en de camera parameters.

Test alle code en los eventuele errors op

\subsection{Blob detectie}
De eerste stap in het navigeren door een doolhof is het vinden van een blob: een gebied in een plaatje dat een bepaalde kleur heeft. In de komende secties zul je je eigen blob-vinder maken.

\subsubsection{Een foto maken en opslaan}
Met behulp van de \textit{getSnapShot()} functie in de tools-module kun je een foto maken met de onderste camera van de robot. Deze functie geeft naast de foto ook extra gegevens terug over de positie van het hoofd. Het eerste argument van de geretourneerde waarde van \textit{getSnapShot()} is het plaatje.

Een gemaakt plaatje kan ook worden opgeslagen. Dit wordt gedaan door de functie \textit{saveImage(name, img)} aan te roepen in de tools-module. Hierin is \textit{name} de bestandsnaam van het plaatje inclusief de bestands-extensie (png of jpg). \textit{img} is het plaatje zelf.

Maak een plaatje en sla dit op. Het opgeslagen bestand kun je vinden in de zelfde map als waar je \textit{config.py}-bestand staat.

Wanneer je het plaatje opent, zul je zien dat de kleuren niet kloppen. Dit klopt, wij gebruiken namelijk de HSV-kleuren representatie in plaats van de algemeen bekende RGB-representatie.
Meer over HSV kun je vinden op: \url{http://nl.wikipedia.org/wiki/HSV_(kleurruimte)}.

\subsubsection{Image filtering}
Een volgende stap in het proces is het filteren van een kleur. Hiervoor moet een functie worden gemaakt die een plaatje en enkele kleur-parameters meekrijgt en een gefilterd zwart/wit plaatje terug geeft.
In dit gefilterde (binaire) plaatje staan witte pixels voor pixels welke in de meegegeven foto voldoen aan onze kleur-eisen en zwarte pixels staan voor pixels die hier niet aan voldoen.

Voordat code kan worden geschreven moet een module worden gemaakt waar straks de code in komt te staan. Maak deze module en registreer het. Zorg er ook voor dat je in je module openCV importeert (\textit{import cv, cv2}) aangezien we deze library gaan gebruiken. Test je systeem op errors.

In de zojuist gemaakte module kan nu de filter-functie worden toegevoegd.
Als input krijgt het een plaatje mee en twee lijsten met elk 3 waardes (minimum en maximum waardes van de Hue, Saturation en Value van een kleur).
Om OpenCV te kunnen laten werken met de kleur-definities, moeten we het omzetten in een Scaler:

\noindent \line(1,0){100}
\begin{verbatim}
minScaler = cv.Scaler(min[0], min[1], min[2], 0)
\end{verbatim}
\noindent \line(1,0){100}
\\\\
Het argument \textit{min} kan worden vervangen door de naam zoals jij de lijst met de minimum waardes hebt genoemd. Beide lijsten moeten worden omgezet naar een scaler.

De filter-functie moet een nieuw plaatje maken, hiervoor moet eerst geheugen worden vrijgemaakt:

\noindent \line(1,0){100}
\begin{verbatim}
resultImg = cv.CreateImage(size, cv.IPL\_DEPTH\_8U, 1)
\end{verbatim}
\noindent \line(1,0){100}
\\\\
Hierin is \textit{size} gelijk aan \textit{(320,240)}, de grootte van de gemaakte foto. \textit{cv.IPL\_DEPTH\_8U} geeft aan dat elke pixel uit het plaatje een 8-bit unsigned waarde heeft. Het aantal dimensies (kleuren) van het plaatje is 1: een pixel is enkel zwart of wit.

We kunnen nu OpenCV gebruiken om een `raw' zwart-wit plaatje te maken van onze foto:

\noindent \line(1,0){100}
\begin{verbatim}
cv.InRangeS(img, minScaler, maxScaler, resultImg)
\end{verbatim}
\noindent \line(1,0){100}
\\\\
Zorg ervoor dat (doormiddel van \textit{return}) de main-modules straks het gefilterde plaatje terug krijgt.
Sla de code up en roep vanuit de main-module de functie aan met een kleur naar keuze

Hoogst waarschijnlijk zul je vele witte vlekken zien in plaatje: ruis. Om dit weg te halen moeten we het plaatje ``smoothen": de overgang tussen zwart/wit maken we minder `hard'. Dit wordt gedaan door steeds een aantal pixels naast elkaar te pakken en daar een gemiddelde waarde van te berekenen. Random witte pixels zullen daardoor een zwarte kleur krijgen en dus wegvallen. De volgende functie doet dit: \textit{cv.Smooth(resultImg, resultImg, cv.CV\_MEDIAN, 1)}. \textit{cv.CV\_MEDIAN} geeft het type ``smoothing" aan en het getal hoeveel naastelkaar gelegen pixels steeds worden gebruikt per berekening. Test een paar verschillende waardes en bepaal welk getal het beste resultaat geeft. \footnote{Op \url{http://opencv.willowgarage.com/documentation/python/image_filtering.html\#smooth} kun je meer vinden over de mogelijke opties van smoothing.}

Als laatste moet het het resulterende plaatje worden omgezet met behulp van het commando: \textit{resultImg = cv.GetMat(resultImg)}. Deze functie zorgt ervoor dat we straks verdere bewerkingen op het plaatje kunnen doen.

\subsubsection{Hough cirkels}
Nu we een gefilterd plaatje krijgen, kunnen we proberen cirkels te zoeken. Hiervoor is een nieuwe functie nodig in onze vision-module. Deze functie heeft (naast \textit{self}) slechts 1 argument: een binair plaatje.

Cirkel detectie doen we doormiddel van een speciaal algorithme: de Hough-transform\footnote{voor meer info check: \url{http://en.wikipedia.org/wiki/Hough_transform}}. Dit algorithme komt met OpenCV geleverd. Om de Hough-transform te kunnen toepassen moet het gegeven plaatje worden omgezet in een array via \textit{numpy} (een python module): \textit{img = numpy.asarray(img)}. Uiteraard moet numpy natuurlijk eerst worden geimporteerd om dit mogelijk te maken (\textit{import numpy}).

De volgende stap is het toepassen van de Hough-transform, hier komen echter veel verschillende parameters bij kijken. Om ervoor te zorgen dat je niet te veel tijd bent aan het tweaken hiervan geven wij je de ``juiste" parameters:

\noindent \line(1,0){100}
\begin{verbatim}
dp = 2
minDist =120
param1 = 255
param2 = 27
minSize = 8
maxSize = 300
circles = cv2.HoughCircles(img, cv.CV_HOUGH_GRADIENT, dp, minDist, None, param1, param2, minSize, maxSize)
\end{verbatim}
\noindent \line(1,0){100}
\\\\
\textit{dp} geeft aan hoe nauwkeurig moet worden gezocht (in ons geval om de 2 pixels), \textit{minDist} geeft aan hoeveel pixels minimaal tussen 2 blobs moet zitten, \textit{param1} en \textit{param2} zijn parameters voor een dieper-liggend proces en \textit{minSize} en \textit{maxSize} geeft aan wat de minimale, danwel de maximale grote van een blob is in pixels.
De output is een lijst met daarin data over de gevonden cirkels (aantal, radius, pixel-center), of \textit{None} indien niks gevonden is.

Sla je code op en test de \textit{HoughCircles} functie. Print het resultaat in de Command Prompt. 

Aan de hand van de geprintte data, kun je nu een systeem maken welke \textit{None} terug geeft als geen cirkel is gevonden of een lijst met coordinaten als er wel cirkels zijn gevonden.

\subsubsection{Meerdere blobs}
Nu we blobs kunnen herkennen en kunnen berekenen waar ze in een plaatje zitten, kunnen we meerdere blobs combineren.

Hiervoor is een functie nodig (in de vision-module) die een plaatje inlaad (geven door de main-module, via \textit{getSnapshot()}), die voor elke kleur blob detectie doet en vervolgens zoekt  naar Hough-Circles. Als output moet de functie een lijst geven met daarin de coordinaten van elke gevonden blob en zijn kleur.

\subsection{Landmark Detectie}
Gefeliciteerd, als je hier ben aangekomen zul je een werkende vision module hebben die blobs kan vinden.

De volgens stap is de mapping van de gevonden blobs naar een landmark en de berekening van de afstand en de hoek tot de landmark.

We beginnen met het berekenen van de afstand tot de landmark: je wilt de robot naar een landmark toe laten lopen en stoppen zodra hij op een bepaalde afstand van de landmark is. Dit is simpel te doen, door de afstand tussen de verschillende blobs te berekenen. Zoals je bij de vorige opdracht gezien hebt is het vision-systeem gevoelig voor ruis. Daarom bereken je een gemiddelde afstand tussen de blobs. 

Om dit te doen moet een functie worden gemaakt in de \texit{vision} module. Deze krijgt als input alle blobs. Als output wordt de gemiddelde afstand in pixels terug gegeven. De functie moet alleen worden aageroepen als er 3 blobs zijn gevonden.

Voor het berekenen van de hoek is onder andere nodig wat het midden is van de landmark. Ook deze functie moet in de \textit{vision}-module worden geplaatst. Als input kijgt hij de posities van de gevonden blobs (kan varieren van 1 tot 3), en als output geeft hij het middelpunt van de set van gevonden blobs. 

De camera van een 





Test nu met de nao en een landmark wat ongeveer de gemiddelde pixel-waarde moet zijn, zodat de nao een halve-blok lengte van de landmark afstaat.

Wanneer de Nao ongeveer op de juiste plek staat, moet de functie de signature (de ID, of het type landmark) terug gegeven m








\subsection{Navigatie}





\end{document}